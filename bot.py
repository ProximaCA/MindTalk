# -*- coding: utf-8 -*-

import asyncio
import os
import sqlite3
import random
import emoji
import base64
from aiogram import Bot, Dispatcher, types
from aiogram.utils import executor
import openai
import torch
import whisper
from aiogram.contrib.middlewares.logging import LoggingMiddleware
from aiogram.dispatcher.filters import Command
from aiogram.types import ParseMode
from aiogram.utils.markdown import hbold, hcode
from aiogram.dispatcher import FSMContext
from aiogram.dispatcher.filters import Command
from aiogram.types import Message

from aiogram.dispatcher.filters import Text
from aiogram.dispatcher import filters

from aiogram.types import ParseMode, ReplyKeyboardRemove
from aiogram.utils.markdown import hbold, hcode, text

from aiogram.types import CallbackQuery

from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

from aiogram.dispatcher import Dispatcher
from aiogram import types

from aiogram.dispatcher import FSMContext
from aiogram.dispatcher.filters.state import State, StatesGroup
from aiogram.contrib.fsm_storage.memory import MemoryStorage

API_TOKEN = ""
OPENAI_API_KEY = ""

openai.api_key = OPENAI_API_KEY

# Initialize bot and dispatcher
bot = Bot(token=API_TOKEN)
storage = MemoryStorage()
dp = Dispatcher(bot, storage=storage)
dp.middleware.setup(LoggingMiddleware())

class Form(StatesGroup):
    sleep_quality = State()  # Will be represented in storage as 'Form:sleep_quality'
    hours_slept = State()  # Will be represented in storage as 'Form:hours_slept'
    bedtime = State()  # Will be represented in storage as 'Form:bedtime'
    wake_time = State()  # Will be represented in storage as 'Form:wake_time'
# Database functions
def create_connection():
    conn = sqlite3.connect('mindtalk.db')
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS messages 
                    (id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER,
                    message TEXT,
                    bot_response TEXT DEFAULT '')''')
    conn.commit()
    return conn


def save_message(conn, user_id, message, bot_response):
    c = conn.cursor()
    c.execute("INSERT INTO messages (user_id, message, bot_response) VALUES (?, ?, ?)", (user_id, message, bot_response))
    conn.commit()

...


def get_messages(conn, user_id):
    c = conn.cursor()
    c.execute("SELECT message FROM messages WHERE user_id=?", (user_id,))
    return c.fetchall()

def clear_journal(conn, user_id):
    c = conn.cursor()
    c.execute("DELETE FROM messages WHERE user_id=?", (user_id,))
    conn.commit()


# Analysis and response functions
async def analyze_journal(journal_text: str) -> str:
    model_engine = "text-davinci-003"
    max_tokens = 1024
    temperature = 0.3

    response = openai.Completion.create(
        engine=model_engine,
        prompt='–í—ã - —É–º–Ω—ã–π –∂—É—Ä–Ω–∞–ª-—Ç–µ—Ä–∞–ø–µ–≤—Ç –ø–æ –∏–º–µ–Ω–∏ MindTalk. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –º–æ—é –∑–∞–ø–∏—Å—å –≤ –¥–Ω–µ–≤–Ω–∏–∫–µ, –¥–∞–π—Ç–µ —Å–æ–≤–µ—Ç—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–∞–º–æ—á—É–≤—Å—Ç–≤–∏—è –∏–ª–∏ —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º. –í—ã–≤–æ–¥—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–π—Ç–µ –≤ –¥–∏–∞–ª–æ–≥–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –≤—Å–µ –æ–±–ª–∞—Å—Ç–∏, –∑–∞–≤–∏—Å—è—â–∏–µ –æ—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ó–∞–ø–∏—Å—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: ' '\n' + journal_text + '\n –°–¥–µ–ª–∞–π –≤—ã–≤–æ–¥—ã –∏ –¥–∞–≤–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–π —Å–º–∞–π–ª–∏–∫–∏ –≤ –¥–∏–∞–ª–æ–≥–µ, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–æ —Ç–∞–∫ –∂–µ –¥–æ–±–∞–≤—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ —Ñ–ª–æ–º–∞—Ç–µ #–∫–ª—é—á–µ–≤–æ–µ—Å–ª–æ–≤–æ',
        max_tokens=max_tokens,
        temperature=temperature,
    )

    analysis = response.choices[0].text.strip()
    return analysis

async def analyze_sleep(prompt: str) -> str:
    model_engine = "text-davinci-002"
    max_tokens = 1024
    temperature = 0.5

    response = openai.Completion.create(
        engine=model_engine,
        prompt=prompt +'–ü—Ä–µ–¥—Å—Ç–≤—å —á—Ç–æ —Ç—ã —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ —Å–Ω—É. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ –¥–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ–∏—Ö –¥–∞–Ω–Ω—ã—Ö. –î–∞–Ω–Ω—ã–µ –≤ —Å—Ä–µ–¥–Ω–µ–º –∑–∞ —Ç—Ä–æ–µ —Å—É—Ç–æ–∫.',
        max_tokens=max_tokens,
        temperature=temperature,
    )

    analysis = response.choices[0].text.strip()
    recommendations = (analysis)

    return "\n".join(recommendations)

async def generate_openai_response(prompt: str) -> str:
    model_engine = "text-davinci-003"
    max_tokens = 1024
    temperature = 0.5

    response = openai.Completion.create(
        engine=model_engine,
        prompt='–í—ã - —É–º–Ω—ã–π –∂—É—Ä–Ω–∞–ª-—Ç–µ—Ä–∞–ø–µ–≤—Ç –ø–æ –∏–º–µ–Ω–∏ MindTalk. –í–µ–¥–∏—Ç–µ —Å–µ–±—è –∫–∞–∫ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø—Å–∏—Ö–æ—Ç–µ—Ä–∞–ø–µ–≤—Ç –Ω–∞ –æ—Ç–ø—É—Å–∫–µ. –ü–æ–º–æ–≥–∏—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Ä–µ—à–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ –≤–æ–ø—Ä–æ—Å—ã, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—è —Ä–∞—Å—Å–ª–∞–±–ª–µ–Ω–Ω—ã–µ —Å–æ–≤–µ—Ç—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª—É—á–∞–π–Ω—ã–µ —ç–º–æ–¥–∑–∏ –≤ —Å–≤–æ–∏—Ö –æ—Ç–≤–µ—Ç–∞—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–æ–ª–µ–µ —É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è. –û–ø–∏—Ä–∞–π—Ç–µ—Å—å –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –æ—Ç–≤–µ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Å–≤–æ–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –∞ —Ç–∞–∫–∂–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–π—Ç–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π.. –ü–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: ' + '\n' + prompt,
        max_tokens=max_tokens,
        temperature=temperature,
    )

    answerai = response.choices[0].text.strip()
    return answerai

# Command handlers
@dp.message_handler(Command("start"))
async def start_message(message: types.Message):
    await message.answer("üëã –Ø —É–º–Ω—ã–π –¥–Ω–µ–≤–Ω–∏–∫ MindTalk. –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –º–Ω–µ –æ —Å–≤–æ–µ–º –¥–Ω–µ, —Ç–∞–∫ –∂–µ —è –º–æ–≥—É –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∞—à–∏ –∑–∞–ø–∏—Å–∏ –∏ —Å–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /help, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –º–æ–∏ —Ñ—É–Ω–∫—Ü–∏–∏!")

@dp.message_handler(Command("help"))
async def help_command(message: types.Message):
    help_text = '''–Ø - MindTalk. –í–æ—Ç –º–æ–∏ —Ñ—É–Ω–∫—Ü–∏–∏:
üöÄ /start - –ù–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å –±–æ—Ç–æ–º.
üìä /analyz - –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∞—à –¥–Ω–µ–≤–Ω–∏–∫ –∏ –¥–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.
‚ùì /agenda - –ù–∞–ø–∏—à—É —Ä–∞—Å—Å–ø–æ—Ä—è–¥–æ–∫ –¥–Ω—è –∏ —Ü–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—à–∏—Ö –∑–∞–ø–∏—Å–µ–π.
üóëÔ∏è /clear - —É–¥–∞–ª–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π –∏–∑ –¥–Ω–µ–≤–Ω–∏–∫–∞. 
üí§ /sleep_analyz - –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∫–∞—á–µ—Å—Ç–≤–∞ —Å–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∞—à–µ–º —Å–Ω–µ.
üéôÔ∏è –ó–∞–ø–∏—Å–∏–≤—ã–π –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏—è —á—Ç–æ–±—ã –Ω–µ –ø–∏—Å–∞—Ç—å –≤—Ä—É—á–Ω—É—é!'''

    await message.answer(help_text)

@dp.message_handler(Command("analyz"))
async def analyze_journal_command(message: types.Message):
    # Get user's messages from the database
    user_id = message.from_user.id
    conn = create_connection()
    messages = get_messages(conn, user_id)
    journal_text = '\n'.join([m[0] for m in messages])

    # Analyze journal
    analysis = await analyze_journal(journal_text)

    # Send result to the user
    await message.answer(analysis)

@dp.message_handler(Command("sleep_analyz"))
async def sleep_analyze_command(message: types.Message):
    # Set state
    await Form.sleep_quality.set()

    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–Ω–µ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    await message.answer("–Ø –º–æ–≥—É –ø–æ–º–æ—á—å –≤–∞–º –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∞—à —Å–æ–Ω. –î–∞–≤–∞–π—Ç–µ –Ω–∞—á–Ω–µ–º —Å –≤–∞—à–∏—Ö –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ç—Ä–µ—Ö –Ω–æ—á–µ–π. –ö–∞–∫ –≤—ã —Å–ø–∞–ª–∏ –∑–∞ —ç—Ç–æ –≤—Ä–µ–º—è? ü§î" + '\n' + "<–û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ, –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–∂–º–∏—Ç–µ 'C–æ–æ–±—â–µ–Ω–∏–µ' –∏ –≤—ã–±–∏—Ä–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é '–û—Ç–≤–µ—Ç–∏—Ç—å'>")
    

@dp.message_handler(state=Form.sleep_quality)
async def process_sleep_quality(message: types.Message, state: FSMContext):
    async with state.proxy() as data:
        data['sleep_quality'] = message.text

    await Form.next()
    await message.answer("–ü–æ —Å–∫–æ–ª—å–∫–æ —á–∞—Å–æ–≤ –≤ —Å—Ä–µ–¥–Ω–µ–º –≤—ã —Å–ø–∏—Ç–µ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å?")


@dp.message_handler(lambda message: not message.text.isdigit(), state=Form.hours_slept)
async def process_hours_slept_invalid(message: types.Message):
    """
    If hours slept is invalid
    """
    return await message.reply("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å–æ–≤ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —á–∏—Å–ª–æ–º. –°–∫–æ–ª—å–∫–æ —á–∞—Å–æ–≤ –≤—ã –ø—Ä–æ—Å–ø–∞–ª–∏?")


@dp.message_handler(lambda message: message.text.isdigit(), state=Form.hours_slept)
async def process_hours_slept(message: types.Message, state: FSMContext):
    async with state.proxy() as data:
        data['hours_slept'] = message.text

    await Form.next()
    await message.answer("–í–æ —Å–∫–æ–ª—å–∫–æ –≤—ã –ª–æ–∂–∏—Ç–µ—Å—å —Å–ø–∞—Ç—å?(–£–∫–∞–∂–∏—Ç–µ 24 —á–∞—Å–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä –≤ 23:00)")


@dp.message_handler(state=Form.bedtime)
async def process_bedtime(message: types.Message, state: FSMContext):
    async with state.proxy() as data:
        data['bedtime'] = message.text

    await Form.next()
    await message.answer("–í–æ —Å–∫–æ–ª—å–∫–æ –≤—ã –ø—Ä–æ—Å—ã–ø–∞–µ—Ç–µ—Å—å?")


@dp.message_handler(state=Form.wake_time)
async def process_wake_time(message: types.Message, state: FSMContext):
    async with state.proxy() as data:
        data['wake_time'] = message.text

        # Combine all user data into a single string and send it to the model for analysis
        full_prompt = f"–ö–∞–∫ —Å–ø–∞–ª–æ—Å—å: {data['sleep_quality']}\n–°–ø–∞–ª {data['hours_slept']} —á–∞—Å–æ–≤, –ª–µ–≥ —Å–ø–∞—Ç—å –≤ {data['bedtime']}, –ø—Ä–æ—Å–Ω—É–ª—Å—è –≤ {data['wake_time']}."
        sleep_analysis = await analyze_sleep(full_prompt)

        # Send the result back to the user
        await message.answer(sleep_analysis)

    # Finish conversation
    await state.finish()

@dp.message_handler(Command("clear"))
async def clear_command(message: types.Message):
    user_id = message.from_user.id
    conn = create_connection()
    clear_journal(conn, user_id)
    conn.close()
    await message.answer("üßπ–í–∞—à –¥–Ω–µ–≤–Ω–∏–∫ –±—ã–ª —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω!")


@dp.message_handler(content_types=['voice'])
async def recognize_voice(message: types.Message):
    import whisper # import whisper module here
    import torch
    # download voice message
    voice_file_id = message.voice.file_id
    voice_file = await bot.get_file(voice_file_id)
    voice_file_path = voice_file.file_path
    await bot.download_file(voice_file_path,'voice.ogg')

    # recognize voice
    model = whisper.load_model('medium')
    audio = whisper.load_audio('voice.ogg')
    audio = whisper.pad_or_trim(audio)
    mel = whisper.log_mel_spectrogram(audio).to(model.device)
    options = whisper.DecodingOptions(language = 'ru')
    result = whisper.decode(model, mel, options)
    recognized_voice_text = result.text
    await message.answer(f'–í–∞—à –∑–∞–ø—Ä–æ—Å –≤—ã–≥–ª—è–¥–∏—Ç —Ç–∞–∫:{recognized_voice_text}')
    # Save user's message to the database
    conn = create_connection()
    save_message(conn, message.from_user.id ,result.text, None)
    conn.close()
    # Generate response
    response_voice_to_text = await generate_openai_response(result.text)
    # Send response to the user
    await message.answer(response_voice_to_text)


@dp.message_handler(content_types=['text'])
async def answer_message(message: types.Message):
    # Generate response
    response_text = await generate_openai_response(message.text)

    conn = create_connection()
    save_message(conn, message.from_user.id, message.text, response_text)
    conn.close()
    # Send response to the user
    await message.answer(response_text)

# Agenda and resources functions
async def recommend_resources(analysis: str) -> str:
    model_engine = "text-davinci-003"
    max_tokens = 1024
    temperature = 0.5

    response = openai.Completion.create(
        engine=model_engine,
        prompt='–ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ, —á—Ç–æ –≤—ã - —É–º–Ω—ã–π –∂—É—Ä–Ω–∞–ª-—Ç–µ—Ä–∞–ø–µ–≤—Ç –ø–æ –∏–º–µ–Ω–∏ MindTalk, –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –º–æ–π –¥–Ω–µ–≤–Ω–∏–∫ –∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏ –≤—ã–∂–∏–º–∫—É.\n' + analysis,
        max_tokens=max_tokens,
        temperature=temperature,
    )

    response_text = response.choices[0].text.strip()
    return response_text

async def generate_agenda(analysis) -> str:
    model_engine = "text-davinci-003"
    max_tokens = 1024
    temperature = 0.5

    response = openai.Completion.create(
        engine=model_engine,
        prompt='–ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ, —á—Ç–æ –≤—ã - —É–º–Ω—ã–π –∂—É—Ä–Ω–∞–ª-—Ç–µ—Ä–∞–ø–µ–≤—Ç –ø–æ –∏–º–µ–Ω–∏ MindTalk, –≤–æ—Ç –º–æ–π —Ä–∞—Å–ø–æ—Ä—è–¥–æ–∫ –¥–Ω—è, —Ü–µ–ª–∏ –∏ –º—ã—Å–ª–∏' + analysis + '\n –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–∫–∞–∂–∏—Ç–µ –º–Ω–µ –º–æ–∏ —Ü–µ–ª–∏ –∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è',
        max_tokens=max_tokens,
        temperature=temperature,
    )

    response_agenda = response.choices[0].text.strip()
    return response_agenda

@dp.message_handler(Command("agenda"))
async def agenda_command(message: types.Message):

    user_id = message.from_user.id
    conn = create_connection()
    messages = get_messages(conn, user_id)
    analysis = '\n'.join([m[0] for m in messages])
    agenda = await generate_agenda(analysis)
    await message.answer(agenda)


# Error handler
@dp.errors_handler(exception=Exception)
async def error_handler(update, exception):
    # Log the error
    if isinstance(exception, openai.error.InvalidRequestError):
        message = exception.args[0]['error']['message']
    else:
        message = str(exception)
    error_msg = f"Error handling the update {update}. \n{message}"
    print(error_msg)

    # Send error message to user
    await bot.send_message(chat_id=update.message.chat.id, text="–ò–∑–≤–∏–Ω–∏—Ç–µ, —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–ø—ã—Ç–∫—É –ø–æ–∑–∂–µ.")

if __name__ == '__main__':
    executor.start_polling(dp, skip_updates=True)
